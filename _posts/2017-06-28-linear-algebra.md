---
layout: post
title: Linear Algebra
categories: ML
---

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
Linear algebra is a key concept when learning many ML principles and a good understanding will help you a lot.

Most people who are interested in ML have likely studied linear algebra at some point either in high school or university so this post isn't intended as an introduction to linear algebra but more as a refresher. If you haven't learned any linear algebra yet I recommend using [Khan Academy](https://www.khanacademy.org/math/linear-algebra).

Linear Algebra typically entails the use of matrices and vectors to represent space and data. In machine learning it is used for things like data manipulation, image recognition, dimensionality reduction and many others.

In this post I'll cover the following main topics relevant to machine learning:
1. Vectors and Matrices
2. Matrix Operations
3. The Unit Vector
3. Transformations
4. Dot and Cross products
5. Matrix Identities, Inverses and Determinants
6. Eigenvectors/Eigenvalues
7. Vector Spaces
8. Real world applications


## 1. Vectors and Matrices

When considering vectors and matrices, intuitively it's best to consider them as representing space, or points in space.

### Vectors

A vector can be defined in multiple ways

### Matrices
